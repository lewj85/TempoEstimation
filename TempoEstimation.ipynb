{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM\n",
    "\n",
    "#from random import random\n",
    "#from numpy import array\n",
    "#from numpy import cumsum\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "#from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "filename = 'asdf'\n",
    "\n",
    "inputs = prep_features(filename)\n",
    "tempos = blah\n",
    "\n",
    "\n",
    "# inputs and outputs\n",
    "nfft = \n",
    "nwin = \n",
    "a1 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a2 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a3 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a4 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a5 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a6 = Input(shape=(nwin,nfft/2 + 1))\n",
    "alist = [a1,a2,a3,a4,a5,a6]\n",
    "a = keras.layers.Concatenate(axis=-1)(alist)\n",
    "\n",
    "def fork (model, n=2):\n",
    "    forks = []\n",
    "    for i in range(n):\n",
    "        f = Sequential()\n",
    "        f.add (model)\n",
    "        forks.append(f)\n",
    "    return forks\n",
    "\n",
    "# fork the inputs\n",
    "left, right = fork(a)\n",
    "\n",
    "# LSTM left branch\n",
    "left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid'))\n",
    "left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid'))\n",
    "left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid'))\n",
    "# LSTM right branch\n",
    "right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid', go_backwards=True))\n",
    "right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid', go_backwards=True))\n",
    "right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid', go_backwards=True))\n",
    "\n",
    "# combine\n",
    "output = Sequential()\n",
    "output.add(Merge([left, right], mode='concat'))\n",
    "# add dense at end - beat or no beat are the 2 units at end\n",
    "output.add(TimeDistributed(Dense(units=2, activation='softmax')))\n",
    "\n",
    "# stochastic gradient descent vs ADAM\n",
    "adm = Adam(lr=0.0001, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "# create computational graph \n",
    "model = Model(inputs=alist, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adm)\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, Y_train, batch_size=1, nb_epoch=nb_epoches, validation_data=(X_test, Y_test), verbose=1, show_accuracy=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 spectrograms\n",
    "\n",
    "import librosa\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "def prep_features(filename):\n",
    "    \n",
    "    x, fs = librosa.load(filename, sr=44100)\n",
    "\n",
    "    # 3 melspectrograms\n",
    "    s1 = librosa.core.stft(x, n_fft=1024, hop_length=441, win_length=1024, window='hamming', center=True, pad_mode='constant')\n",
    "    ms1 = librosa.feature.melspectrogram(sr=44100, S=s1)\n",
    "    s2 = librosa.core.stft(x, n_fft=2048, hop_length=441, win_length=2048, window='hamming', center=True, pad_mode='constant')\n",
    "    ms2 = librosa.feature.melspectrogram(sr=44100, S=s2)\n",
    "    s3 = librosa.core.stft(x, n_fft=4096, hop_length=441, win_length=4096, window='hamming', center=True, pad_mode='constant')\n",
    "    ms3 = librosa.feature.melspectrogram(sr=44100, S=s3)\n",
    "\n",
    "    # 3 median spectrograms\n",
    "    # pad edges\n",
    "    p1 = numpy.pad(ms1, ((0,0),(0,1024//2)), 'reflect')\n",
    "    p2 = numpy.pad(ms2, ((0,0),(0,2048//2)), 'reflect')\n",
    "    p3 = numpy.pad(ms3, ((0,0),(0,4096//2)), 'reflect')\n",
    "    # cut off the non-causal median leftover from the end\n",
    "    m1 = medfilt(p1, kernel_size=(1,1024//100))[:-1024/2]\n",
    "    m2 = medfilt(p2, kernel_size=(1,2048//100))[:-2048/2]\n",
    "    m3 = medfilt(p3, kernel_size=(1,4096//100))[:-4096/2]\n",
    "    # half-wave rectify\n",
    "    h1 = np.maximum(ms1-m1,0)\n",
    "    h2 = np.maximum(ms2-m2,0)\n",
    "    h3 = np.maximum(ms3-m3,0)\n",
    "\n",
    "    return ms1, ms2, ms3, h1, h2, h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "def cnn(x, num_steps, win_size=1024, weight_decay=0.01):\n",
    "\n",
    "    a = Input(shape=(num_steps, win_size))\n",
    "    filters = 256\n",
    "    kernel_size = 128\n",
    "    net = Conv1D(filters, kernel_size, strides=4, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=keras.regularizers.l2(weight_decay))(a)\n",
    "    net = Conv1D(filters, kernel_size, strides=4, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=keras.regularizers.l2(weight_decay))(net)\n",
    "    net = Conv1D(filters, kernel_size, strides=4, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=keras.regularizers.l2(weight_decay))(net)\n",
    "    # remove channel dimension\n",
    "    net = Flatten(data_format='channels_last')(net)\n",
    "    \n",
    "    net = Dense(units=128, activation='linear')\n",
    "\n",
    "def fork (model, n=2):\n",
    "    \n",
    "    forks = []\n",
    "    for i in range(n):\n",
    "        f = Sequential()\n",
    "        f.add (model)\n",
    "        forks.append(f)\n",
    "        \n",
    "    return forks\n",
    "\n",
    "\n",
    "def bilstm(inputs):\n",
    "\n",
    "    # fork the inputs\n",
    "    left, right = fork(inputs)\n",
    "\n",
    "    # LSTM left branch\n",
    "    left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid'))\n",
    "    left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid'))\n",
    "    left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid'))\n",
    "    # LSTM right branch\n",
    "    right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid', go_backwards=True))\n",
    "    right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid', go_backwards=True))\n",
    "    right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid', go_backwards=True))\n",
    "\n",
    "    # combine\n",
    "    output = Sequential()\n",
    "    output.add(Merge([left, right], mode='concat'))\n",
    "    # add dense at end - beat or no beat are the 2 units at end\n",
    "    output.add(TimeDistributed(Dense(units=2, activation='softmax')))\n",
    "    \n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
