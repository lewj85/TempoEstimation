{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BiLSTM\n",
    "\n",
    "#from random import random\n",
    "#from numpy import array\n",
    "#from numpy import cumsum\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import TimeDistributed\n",
    "#from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "filename = 'asdf'\n",
    "\n",
    "inputs = prep_features(filename)\n",
    "tempos = blah\n",
    "\n",
    "\n",
    "# inputs and outputs\n",
    "nfft = \n",
    "nwin = \n",
    "a1 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a2 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a3 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a4 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a5 = Input(shape=(nwin,nfft/2 + 1))\n",
    "a6 = Input(shape=(nwin,nfft/2 + 1))\n",
    "alist = [a1,a2,a3,a4,a5,a6]\n",
    "a = keras.layers.Concatenate(axis=-1)(alist)\n",
    "\n",
    "def fork (model, n=2):\n",
    "    forks = []\n",
    "    for i in range(n):\n",
    "        f = Sequential()\n",
    "        f.add (model)\n",
    "        forks.append(f)\n",
    "    return forks\n",
    "\n",
    "# fork the inputs\n",
    "left, right = fork(a)\n",
    "\n",
    "# LSTM left branch\n",
    "left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid'))\n",
    "left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid'))\n",
    "left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid'))\n",
    "# LSTM right branch\n",
    "right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid', go_backwards=True))\n",
    "right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid', go_backwards=True))\n",
    "right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "               forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "               inner_activation='sigmoid', go_backwards=True))\n",
    "\n",
    "# combine\n",
    "output = Sequential()\n",
    "output.add(Merge([left, right], mode='concat'))\n",
    "# add dense at end - beat or no beat are the 2 units at end\n",
    "output.add(TimeDistributed(Dense(units=2, activation='softmax')))\n",
    "\n",
    "# stochastic gradient descent vs ADAM\n",
    "adm = Adam(lr=0.0001, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "\n",
    "# create computational graph \n",
    "model = Model(inputs=alist, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adm)\n",
    "\n",
    "print(\"Train...\")\n",
    "model.fit(X_train, Y_train, batch_size=1, nb_epoch=nb_epoches, validation_data=(X_test, Y_test), verbose=1, show_accuracy=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 spectrograms\n",
    "\n",
    "import librosa\n",
    "from scipy.signal import medfilt\n",
    "\n",
    "def prep_features(x, fs):\n",
    "    \n",
    "    #x, fs = librosa.load(filename, sr=44100)\n",
    "\n",
    "    # 3 melspectrograms\n",
    "    s1 = librosa.core.stft(x, n_fft=1024, hop_length=441, win_length=1024, window='hamming', center=True, pad_mode='constant')\n",
    "    ms1 = librosa.feature.melspectrogram(sr=44100, S=s1)\n",
    "    s2 = librosa.core.stft(x, n_fft=2048, hop_length=441, win_length=2048, window='hamming', center=True, pad_mode='constant')\n",
    "    ms2 = librosa.feature.melspectrogram(sr=44100, S=s2)\n",
    "    s3 = librosa.core.stft(x, n_fft=4096, hop_length=441, win_length=4096, window='hamming', center=True, pad_mode='constant')\n",
    "    ms3 = librosa.feature.melspectrogram(sr=44100, S=s3)\n",
    "\n",
    "    # 3 median spectrograms\n",
    "    # pad edges\n",
    "    p1 = numpy.pad(ms1, ((0,0),(0,1024//2)), 'reflect')\n",
    "    p2 = numpy.pad(ms2, ((0,0),(0,2048//2)), 'reflect')\n",
    "    p3 = numpy.pad(ms3, ((0,0),(0,4096//2)), 'reflect')\n",
    "    # cut off the non-causal median leftover from the end\n",
    "    m1 = medfilt(p1, kernel_size=(1,1024//100))[:-1024/2]\n",
    "    m2 = medfilt(p2, kernel_size=(1,2048//100))[:-2048/2]\n",
    "    m3 = medfilt(p3, kernel_size=(1,4096//100))[:-4096/2]\n",
    "    # half-wave rectify\n",
    "    h1 = np.maximum(ms1-m1,0)\n",
    "    h2 = np.maximum(ms2-m2,0)\n",
    "    h3 = np.maximum(ms3-m3,0)\n",
    "\n",
    "    return ms1, ms2, ms3, h1, h2, h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Flatten\n",
    "\n",
    "def cnn(x, num_steps, win_size=1024, weight_decay=0.01):\n",
    "\n",
    "    a = Input(shape=(num_steps, win_size))\n",
    "    filters = 256\n",
    "    kernel_size = 128\n",
    "    net = Conv1D(filters, kernel_size, strides=4, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=keras.regularizers.l2(weight_decay))(a)\n",
    "    net = Conv1D(filters, kernel_size, strides=4, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=keras.regularizers.l2(weight_decay))(net)\n",
    "    net = Conv1D(filters, kernel_size, strides=4, kernel_initializer='he_normal',\n",
    "               kernel_regularizer=keras.regularizers.l2(weight_decay))(net)\n",
    "    # remove channel dimension\n",
    "    net = Flatten(data_format='channels_last')(net)\n",
    "    \n",
    "    net = Dense(units=128, activation='linear')\n",
    "\n",
    "def fork (model, n=2):\n",
    "    \n",
    "    forks = []\n",
    "    for i in range(n):\n",
    "        f = Sequential()\n",
    "        f.add (model)\n",
    "        forks.append(f)\n",
    "        \n",
    "    return forks\n",
    "\n",
    "\n",
    "def bilstm(inputs):\n",
    "\n",
    "    # fork the inputs\n",
    "    left, right = fork(inputs)\n",
    "\n",
    "    # LSTM left branch\n",
    "    left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid'))\n",
    "    left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid'))\n",
    "    left.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid'))\n",
    "    # LSTM right branch\n",
    "    right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid', go_backwards=True))\n",
    "    right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid', go_backwards=True))\n",
    "    right.add(LSTM(output_dim=hidden_units, init='uniform', inner_init='uniform',\n",
    "                   forget_bias_init='one', return_sequences=True, activation='tanh',\n",
    "                   inner_activation='sigmoid', go_backwards=True))\n",
    "\n",
    "    # combine\n",
    "    output = Sequential()\n",
    "    output.add(Merge([left, right], mode='concat'))\n",
    "    # add dense at end - beat or no beat are the 2 units at end\n",
    "    output.add(TimeDistributed(Dense(units=2, activation='softmax')))\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beats': array([  20064,   46050,   71272,   97640,  124678,  152018,  178895,\n",
      "        204642,  231774,  258143,  284129,  310879,  338012,  365144,\n",
      "        390748,  416352,  443600,  468821,  497669,  524233,  550219,\n",
      "        576205,  603338,  629324,  656839,  683207,  709957,  736326,\n",
      "        763076,  789445,  816195,  842563,  868282,  895032,  921401,\n",
      "        948151,  973373, 1000505, 1025345, 1051713, 1078846, 1106361,\n",
      "       1132347, 1158715, 1185848, 1212565, 1238708, 1264363, 1291428,\n",
      "       1317804, 1343790, 1370922, 1396909, 1422513, 1448881, 1474867,\n",
      "       1501617, 1529132, 1555118, 1582633, 1608619, 1634987, 1660209,\n",
      "       1687552, 1714971, 1740985, 1766769, 1793312, 1820827, 1847577,\n",
      "       1872799, 1899549, 1926682, 1953050, 1979418, 2006169, 2032919,\n",
      "       2060434, 2085656, 2111260, 2139017, 2166863, 2193785, 2219367,\n",
      "       2246450, 2272848, 2298559, 2323586, 2349983, 2376380, 2402092,\n",
      "       2429518, 2456258, 2483805]), 'tempo': 99.9563288322695}\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "def load_annotations(filename):\n",
    "\n",
    "    x = loadmat(filename)\n",
    "    beats = x['datarec'][10]\n",
    "    tempo = x['datarec'][8]\n",
    "\n",
    "    y = beats[0].flatten()\n",
    "    d = {\n",
    "        'beats':y,\n",
    "        'tempo':tempo[0][0][0]\n",
    "    }\n",
    "    return d\n",
    "\n",
    "#print(prep_data(\"./dataset/info/001_info.mat\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "\n",
    "def prep_hainsworth_data(info_dir, sample_dir):\n",
    "    audio_array = []\n",
    "    label_array = []\n",
    "\n",
    "    #infodir = \"./info/\"\n",
    "    #sampledir = \"./samples/\"\n",
    "\n",
    "    for i in range(245):\n",
    "        # {} for replacement, : format spec, 03 pad up to 3 leading 0s, d is int\n",
    "        filename1 = \"{:03d}_info.mat\".format(i)\n",
    "        filename2 = \"{:03d}.wav\".format(i)\n",
    "\n",
    "        f1 = os.path.join(info_dir, filename1)\n",
    "        f2 = os.path.join(sample_dir, filename2)\n",
    "        if os.path.exists(f1) and os.path.exists(f2):\n",
    "            # TODO: hopsize and target sample rate\n",
    "            x, fs = librosa.load(f2, sr=None)\n",
    "            r = load_annotations(f1)\n",
    "            audio_array.append(x)\n",
    "            label_array.append(r) # has tempos too\n",
    "\n",
    "    return audio_array, label_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dir = \"./info/\"\n",
    "sample_dir = \"./samples/\"\n",
    "hop_size = 1234\n",
    "target_fs = 1234\n",
    "\n",
    "# prepare the data\n",
    "a, r = prep_hainsworth_data(info_dir, sample_dir, hop_size, target_fs)\n",
    "#a, r = prep_ballroom_data(info_dir, sample_dir, hop_size, target_fs)\n",
    "\n",
    "# 6 spectrograms\n",
    "spectrogram_array = []\n",
    "for i in a:\n",
    "    spectrogram_array.append(prep_features(i, target_fs))\n",
    "\n",
    "# create BiLSTM and dense\n",
    "\n",
    "# batch dataset\n",
    "\n",
    "# training\n",
    "\n",
    "# testing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
